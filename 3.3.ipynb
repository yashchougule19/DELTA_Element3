{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('datasets/btc_tweets_train.parquet.gzip')\n",
    "test_df = pd.read_parquet('datasets/btc_tweets_test.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index()\n",
    "test_df = test_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.rename(columns={test_df.columns[0]: 'tweet ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   content    1500 non-null   object\n",
      " 1   username   1500 non-null   object\n",
      " 2   sentiment  1500 non-null   bool  \n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 25.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1500, 3),\n",
       " 0,\n",
       " None,\n",
       "                                              content      username  sentiment\n",
       " 0  $Bitcoin TO $100,000 SOONER THAN YOU THINKâ€¼ï¸ðŸ’¯ðŸ™...   BezosCrypto       True\n",
       " 1  Alright I have my rares. Who else is grabbing ...   spartantc81       True\n",
       " 2  Bitcoin (BTC) Targets Over $100,000 as This Im...   BezosCrypto       True\n",
       " 3  ðŸ“¢ Xverse Web-based pool is live:\\n\\nâ€¢Update @x...  godfred_xcuz       True\n",
       " 4  Yesterday, a Bitcoin projection was displayed ...   goddess81oo       True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_info(df):\n",
    "    return df.shape, df.isnull().sum().sum(), df.info(), df.head()\n",
    "\n",
    "df_info(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['tweet ID', 'user_displayname', 'hashtags'], axis=1)\n",
    "test_df = test_df.drop(['tweet ID', 'user_displayname', 'hashtags'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import emoji\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, df, content_column, sentiment_column):\n",
    "        \"\"\"\n",
    "        Initialize the DataPreprocessor class with the DataFrame and relevant columns.\n",
    "\n",
    "        Parameters:\n",
    "        - df: pd.DataFrame\n",
    "            The DataFrame containing the dataset.\n",
    "        - content_column: str\n",
    "            The name of the column containing the text content to analyze.\n",
    "        - sentiment_column: str\n",
    "            The name of the column containing the sentiment labels.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.content_column = content_column\n",
    "        self.sentiment_column = sentiment_column\n",
    "    \n",
    "    def remove_similar_content(self, similarity_threshold=0.65):\n",
    "        \"\"\"\n",
    "        Removes samples with similar content based on cosine similarity.\n",
    "\n",
    "        Parameters:\n",
    "        - similarity_threshold: float (default=0.65)\n",
    "            The threshold for cosine similarity above which samples are considered similar.\n",
    "        \"\"\"\n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        tfidf_matrix = tfidf.fit_transform(self.df[self.content_column])\n",
    "        cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "        indices_to_remove = set()\n",
    "\n",
    "        for i in range(len(cosine_sim)):\n",
    "            for j in range(i + 1, len(cosine_sim)):\n",
    "                if cosine_sim[i, j] > similarity_threshold:\n",
    "                    indices_to_remove.add(i)\n",
    "                    indices_to_remove.add(j)\n",
    "\n",
    "        self.df = self.df.drop(index=indices_to_remove).reset_index(drop=True)\n",
    "        return self.df\n",
    "\n",
    "    def clean_text(self):\n",
    "        \"\"\"\n",
    "        Cleans text data by removing punctuation, stopwords, and applying lemmatization.\n",
    "        \"\"\"\n",
    "        nltk.download('stopwords')\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        def clean(tweet):\n",
    "            # Convert emojis to text # Converts emojis to text, e.g., \"ðŸ˜Š\" becomes \":smiling_face:\"\n",
    "            tweet = emoji.demojize(tweet, delimiters=(\" \", \" \"))\n",
    "            # Remove links\n",
    "            tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
    "            # Remove punctuation and numbers\n",
    "            tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
    "            # Tokenize\n",
    "            words = nltk.word_tokenize(tweet)\n",
    "            # Remove stop words\n",
    "            words = [word for word in words if word.lower() not in stop_words]\n",
    "            # Lemmatize words\n",
    "            lemmatizer = nltk.WordNetLemmatizer()\n",
    "            words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "            return ' '.join(words)\n",
    "        \n",
    "        self.df['cleaned_content'] = self.df[self.content_column].apply(clean)\n",
    "        return self.df\n",
    "    \n",
    "    def handle_class_imbalance_with_SMOTE(self):\n",
    "        \"\"\"\n",
    "        Handles class imbalance using SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "        \"\"\"\n",
    "        \n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        X = tfidf.fit_transform(self.df[self.content_column])\n",
    "        y = self.df[self.sentiment_column]\n",
    "        \n",
    "        # Apply SMOTE to the vectorized text\n",
    "        smote = SMOTE(random_state=21)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        self.df = pd.DataFrame(X_resampled.toarray(), columns=tfidf.get_feature_names_out())\n",
    "        self.df[self.sentiment_column] = y_resampled\n",
    "        return self.df\n",
    "\n",
    "    def preprocess(self, remove_similar=True, balance_classes=True, clean_text=True):\n",
    "        \"\"\"\n",
    "        Performs the full preprocessing pipeline.\n",
    "\n",
    "        Parameters:\n",
    "        - remove_similar: bool (default=True)\n",
    "            Whether to remove similar content.\n",
    "        - balance_classes: bool (default=True)\n",
    "            Whether to handle class imbalance.\n",
    "        - clean_text: bool (default=True)\n",
    "            Whether to clean text data.\n",
    "        \"\"\"\n",
    "        if remove_similar:\n",
    "            self.remove_similar_content()\n",
    "        if balance_classes:\n",
    "            self.handle_class_imbalance_with_SMOTE()\n",
    "        if clean_text:\n",
    "            self.clean_text()\n",
    "\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the class object for 'train' dataset\n",
    "train_preprocesser = DataPreprocessor(df=train_df, content_column='content', sentiment_column='sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Diya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "cleaned_train_df = train_preprocesser.preprocess(remove_similar=True, balance_classes=False, clean_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the class object for 'test' dataset\n",
    "test_preprocesser = DataPreprocessor(df=test_df, content_column='content', sentiment_column='sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Diya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "cleaned_test_df = test_preprocesser.preprocess(remove_similar=True, balance_classes=False, clean_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1399, 4), (475, 4))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df.shape, cleaned_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>username</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alright I have my rares. Who else is grabbing ...</td>\n",
       "      <td>spartantc81</td>\n",
       "      <td>True</td>\n",
       "      <td>alright rares else grabbing dogepunksbtc disco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ðŸ“¢ Xverse Web-based pool is live:\\n\\nâ€¢Update @x...</td>\n",
       "      <td>godfred_xcuz</td>\n",
       "      <td>True</td>\n",
       "      <td>loudspeaker xverse webbased pool live update x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yesterday, a Bitcoin projection was displayed ...</td>\n",
       "      <td>goddess81oo</td>\n",
       "      <td>True</td>\n",
       "      <td>yesterday bitcoin projection displayed europea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unpopular opinion:\\n\\nThis pump isnâ€™t going to...</td>\n",
       "      <td>CloseSomeSayles</td>\n",
       "      <td>False</td>\n",
       "      <td>unpopular opinion pump isnt going stop enterin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Bitcoin fixes this</td>\n",
       "      <td>ShannenJPEG</td>\n",
       "      <td>True</td>\n",
       "      <td>bitcoin fix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content         username  \\\n",
       "0  Alright I have my rares. Who else is grabbing ...      spartantc81   \n",
       "1  ðŸ“¢ Xverse Web-based pool is live:\\n\\nâ€¢Update @x...     godfred_xcuz   \n",
       "2  Yesterday, a Bitcoin projection was displayed ...      goddess81oo   \n",
       "3  Unpopular opinion:\\n\\nThis pump isnâ€™t going to...  CloseSomeSayles   \n",
       "4                                #Bitcoin fixes this      ShannenJPEG   \n",
       "\n",
       "   sentiment                                    cleaned_content  \n",
       "0       True  alright rares else grabbing dogepunksbtc disco...  \n",
       "1       True  loudspeaker xverse webbased pool live update x...  \n",
       "2       True  yesterday bitcoin projection displayed europea...  \n",
       "3      False  unpopular opinion pump isnt going stop enterin...  \n",
       "4       True                                        bitcoin fix  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentiment\n",
       " True     1125\n",
       " False     274\n",
       " Name: count, dtype: int64,\n",
       " sentiment\n",
       " True     379\n",
       " False     96\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df['sentiment'].value_counts(), cleaned_test_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: both the cleaned datasets above are still imbalanced with True values largly outnumbered than False. The imbalance needs to be taken care of by assigning class weights dring model training.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Benchmark: vaderSentiment Sentiment Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DELTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
