{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure for Data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, df, content_column, sentiment_column):\n",
    "        \"\"\"\n",
    "        Initialize the DataPreprocessor class with the DataFrame and relevant columns.\n",
    "\n",
    "        Parameters:\n",
    "        - df: pd.DataFrame\n",
    "            The DataFrame containing the dataset.\n",
    "        - content_column: str\n",
    "            The name of the column containing the text content to analyze.\n",
    "        - sentiment_column: str\n",
    "            The name of the column containing the sentiment labels.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.content_column = content_column\n",
    "        self.sentiment_column = sentiment_column\n",
    "    \n",
    "    def remove_similar_content(self, similarity_threshold=0.8):\n",
    "        \"\"\"\n",
    "        Removes samples with similar content based on cosine similarity.\n",
    "\n",
    "        Parameters:\n",
    "        - similarity_threshold: float (default=0.8)\n",
    "            The threshold for cosine similarity above which samples are considered similar.\n",
    "        \"\"\"\n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        tfidf_matrix = tfidf.fit_transform(self.df[self.content_column])\n",
    "        cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "        indices_to_remove = set()\n",
    "\n",
    "        for i in range(len(cosine_sim)):\n",
    "            for j in range(i + 1, len(cosine_sim)):\n",
    "                if cosine_sim[i, j] > similarity_threshold:\n",
    "                    indices_to_remove.add(i)\n",
    "                    indices_to_remove.add(j)\n",
    "\n",
    "        self.df = self.df.drop(index=indices_to_remove).reset_index(drop=True)\n",
    "\n",
    "    def handle_class_imbalance(self):\n",
    "        \"\"\"\n",
    "        Handles class imbalance using SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "        \"\"\"\n",
    "        smote = SMOTE()\n",
    "        X = self.df[self.content_column]\n",
    "        y = self.df[self.sentiment_column]\n",
    "\n",
    "        X_resampled, y_resampled = smote.fit_resample(X.values.reshape(-1, 1), y)\n",
    "\n",
    "        self.df = pd.DataFrame({self.content_column: X_resampled.flatten(), self.sentiment_column: y_resampled})\n",
    "\n",
    "    def clean_text(self):\n",
    "        \"\"\"\n",
    "        Cleans text data by removing punctuation, stopwords, and applying lemmatization.\n",
    "        \"\"\"\n",
    "        nltk.download('stopwords')\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        def clean(sentence):\n",
    "            # Remove punctuation and numbers\n",
    "            sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "            # Tokenize\n",
    "            words = nltk.word_tokenize(sentence)\n",
    "            # Remove stop words\n",
    "            words = [word for word in words if word.lower() not in stop_words]\n",
    "            # Lemmatize words\n",
    "            lemmatizer = nltk.WordNetLemmatizer()\n",
    "            words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "            return ' '.join(words)\n",
    "        \n",
    "        self.df[self.content_column] = self.df[self.content_column].apply(clean)\n",
    "\n",
    "    def preprocess(self, remove_similar=True, balance_classes=True, clean_text=True):\n",
    "        \"\"\"\n",
    "        Performs the full preprocessing pipeline.\n",
    "\n",
    "        Parameters:\n",
    "        - remove_similar: bool (default=True)\n",
    "            Whether to remove similar content.\n",
    "        - balance_classes: bool (default=True)\n",
    "            Whether to handle class imbalance.\n",
    "        - clean_text: bool (default=True)\n",
    "            Whether to clean text data.\n",
    "        \"\"\"\n",
    "        if remove_similar:\n",
    "            self.remove_similar_content()\n",
    "        if balance_classes:\n",
    "            self.handle_class_imbalance()\n",
    "        if clean_text:\n",
    "            self.clean_text()\n",
    "\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is `df`, with 'content' as the text column and 'sentiment' as the label column\n",
    "preprocessor = DataPreprocessor(df, content_column='content', sentiment_column='sentiment')\n",
    "\n",
    "# To run the full preprocessing pipeline:\n",
    "df_processed = preprocessor.preprocess()\n",
    "\n",
    "# If you only want to run specific steps, you can pass parameters:\n",
    "# For example, to remove similar content and clean text but skip class imbalance handling:\n",
    "df_processed = preprocessor.preprocess(balance_classes=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
